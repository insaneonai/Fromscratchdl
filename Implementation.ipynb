{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7yJDMCF1Ti7gKIvD4jXEs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/insaneonai/Fromscratchdl/blob/main/Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation of Resnet using Pytorch ðŸ¤—"
      ],
      "metadata": {
        "id": "GJNqebSJnbGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "u7mCMb965tql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.7,0.7,0.7),(0.7,0.7,0.7))  ## Normalize to Mean and standard deviation.\n",
        "])"
      ],
      "metadata": {
        "id": "fs671O5L6iPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "batch_size = 8\n",
        "\n",
        "train_set = torchvision.datasets.CIFAR10(root=\"/content/\",train=True,transform=transforms,download=True)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_set,batch_size=batch_size,shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFeCQFE37fty",
        "outputId": "acccc339-6038-42e5-e90d-19fed9b38f54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170498071/170498071 [00:10<00:00, 15724388.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/cifar-10-python.tar.gz to /content/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = torchvision.datasets.CIFAR10(root=\"/content/\",train=False,transform=transforms,download=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_set,batch_size=batch_size,shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaMUDrc-8yXD",
        "outputId": "f5d165df-1036-49b6-99ea-e47a3aab4cdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "DgcPpwY98NPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "  def __init__(self,in_channels,out_channels,stride=1,downsampler=None):\n",
        "    super().__init__()\n",
        "    self.expansion = 4\n",
        "    self.conv1 = nn.Conv2d(in_channels,out_channels,1,1,0,bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "    self.conv2 = nn.Conv2d(out_channels,out_channels,3,stride,padding=1,bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "    self.conv3 = nn.Conv2d(out_channels,out_channels*self.expansion,1,1,padding=0,bias=False)\n",
        "    self.bn3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
        "    self.gelu = nn.GELU()\n",
        "    self.downsampler = downsampler\n",
        "\n",
        "  def forward(self,x):\n",
        "    clone = x.clone()\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.gelu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.gelu(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.bn3(x)\n",
        "\n",
        "    if self.downsampler:\n",
        "      print(\"Using Downsampler\")\n",
        "      clone = self.downsampler(clone)\n",
        "    print(\"clone shape: \", clone.shape, \"x shape: \",x.shape)\n",
        "    x += clone\n",
        "    x = self.gelu(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "80YhAXMz90NB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RESNet(nn.Module):\n",
        "  def __init__(self,block,img_channels,num_blocks_per_layer,out_class):\n",
        "    super().__init__()\n",
        "    self.in_channels = 64\n",
        "    self.conv = nn.Conv2d(img_channels,64,kernel_size=7,stride=2,padding=3,bias=False)\n",
        "    self.bn = nn.BatchNorm2d(64)\n",
        "    self.gelu = nn.GELU()\n",
        "    self.maxpool = nn.MaxPool2d(3,stride=2,padding=1)\n",
        "\n",
        "    self.layer1 = self.create_layer(block,num_blocks_per_layer[0],64,1)\n",
        "    self.layer2 = self.create_layer(block,num_blocks_per_layer[1],64*2,2)\n",
        "    self.layer3 = self.create_layer(block,num_blocks_per_layer[2],64*3,2)\n",
        "    self.layer4 = self.create_layer(block,num_blocks_per_layer[3],64*4,2)\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "    self.drouput = torch.nn.Dropout(p=0.5, inplace=False)\n",
        "    self.fc = nn.Linear(512*2,out_class)\n",
        "  def forward(self,x):\n",
        "    x = self.conv(x)\n",
        "    x = self.bn(x)\n",
        "    x = self.gelu(x)\n",
        "    x = self.maxpool(x)\n",
        "    x = self.layer1(x)\n",
        "    x = self.drouput(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.drouput(x)\n",
        "    x = self.layer3(x)\n",
        "    x = self.drouput(x)\n",
        "    x = self.layer4(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = x.reshape(x.shape[0], -1)\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "  def create_layer(self,block,num_blocks,channels,stride):\n",
        "    ## Must check condition to add x with F(x).\n",
        "    downsample = None\n",
        "    layers = []\n",
        "    if stride !=1 or self.in_channels != channels * 4:\n",
        "      downsample = nn.Sequential(nn.Conv2d(self.in_channels,channels * 4, 1, stride),\n",
        "                                 nn.BatchNorm2d(channels * 4))\n",
        "\n",
        "    layers.append(block(self.in_channels,channels,stride,downsample))\n",
        "    self.in_channels = channels * 4\n",
        "    for i in range(num_blocks-1):\n",
        "      layers.append(block(self.in_channels,channels))\n",
        "    return nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "d7vGDCrDIpCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResNet50(img_channel=3, num_classes=10):\n",
        "    return RESNet(Block, img_channel, [3, 4, 6, 3], num_classes)"
      ],
      "metadata": {
        "id": "NxJsgaRoO7Ru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet = ResNet50()"
      ],
      "metadata": {
        "id": "2cXwEimQxkfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_set))[0].reshape(1,3,32,32)"
      ],
      "metadata": {
        "id": "XFio7oe21UVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = next(iter(train_set))[0]\n",
        "b = next(iter(train_set))[0]"
      ],
      "metadata": {
        "id": "jDG6uXn02SVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "    net = ResNet50(img_channel=3, num_classes=10)\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    y = net(torch.randn(4, 3, 224, 224)).to(device)\n",
        "    print(y.size())"
      ],
      "metadata": {
        "id": "3Ue5Z-V9xyHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "CXL7iBtiCten"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}